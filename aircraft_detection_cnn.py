# -*- coding: utf-8 -*-
"""aircraft detection CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dygZOqyu34cYzn9SANSdnCJS1_WoGNsx
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install colorama
!pip install keras_tuner

!pip install tensorflow scikit-learn pydot graphviz

import pandas as pd
import numpy as np
import os
import xml.etree.ElementTree as ET
from colorama import Fore, Back, Style
import random
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from PIL import Image, ImageDraw
import itertools
from sklearn.preprocessing import OneHotEncoder
import keras_tuner as kt
from tensorflow.keras.utils import plot_model, model_to_dot
from IPython.display import SVG
from sklearn.metrics import recall_score, precision_score, jaccard_score

# Read annotations from an xml file
def read_annotations(xml_path):
    '''
    This function reads the ‘xml’ files containing the annotations
    Input: path to the xml file
    Output: a list containing the label and the annotations
    '''
    # Parse the XML file
    tree = ET.parse(xml_path)

    # Get the root element of the XML tree
    root = tree.getroot()

    # Initialize an empty list to store the annotations
    annotations = []

    # Loop through <object> elements in the XML
    for obj in root.findall('object'):

        # Extract the label from the <name> element
        name = obj.find('name').text

        # Extract the bounding box coordinates from the <bndbox> element
        bbox = obj.find('bndbox')
        xmin = int(bbox.find('xmin').text)
        ymin = int(bbox.find('ymin').text)
        xmax = int(bbox.find('xmax').text)
        ymax = int(bbox.find('ymax').text)
        annotations.append((name, (xmin, ymin, xmax, ymax)))

    # Return the list of annotations
    return annotations

def read_data(file_names):
    '''
    This function reads the images from the files.
    Returns a tuple:
    data: The data with images an corresponding annotations
    dims: List of all dimensions encountered throughout the dataset
    '''
    # Initialize two empty lists
    data = []
    dims = []

    # Loop over the file names extracted and read the images and annotations
    for file_name in file_names:

        # Get the paths to the files
        img_path = os.path.join(data_dir, 'JPEGImages',
                                file_name + '.jpg')
        xml_path = os.path.join(data_dir, 'Annotations',
                                'Horizontal Bounding Boxes',
                                file_name + '.xml')

        # Read the image
        img = Image.open(img_path)

        # Exclude 4-channel images
        if (np.array(img).shape[2]) != 3:
            continue

        # Extract annotations
        annotations = read_annotations(xml_path)

        # Get the dimensions of all objects and store it for later use
        for annot in annotations:
            width = abs(annot[1][0] - annot[1][2])
            height = abs(annot[1][1] - annot[1][3])
            dims.append(width)
            dims.append(height)

        data.append((img, annotations))


    return data, dims

# Define the path to the data directory
data_dir = '/content/drive/MyDrive/MAR20'
# Read the train and test filenames from the ImageSets/Main folder
with open(os.path.join(data_dir, 'ImageSets/Main/train.txt'), 'r') as f:
    train_filenames = f.read().splitlines()
train_data, train_obj_dims = read_data(train_filenames)

'''
####################### TEST SET #######################
with open(os.path.join(data_dir, 'ImageSets/Main/test.txt'), 'r') as f:
    test_filenames = f.read().splitlines()
test_data, test_obj_dims = read_data(test_filenames)
'''


# Display an exmple
img = train_data[0][0]
draw = ImageDraw.Draw(img)
objects = train_data[0][1]
for obj in objects:
    draw.rectangle(obj[1], outline='red')
    draw.text((obj[1][0], obj[1][1]), obj[0], fill='red')
img

def pad_img(img):
    '''
    This function transforms an image to the desired size.
    If squared, the image remains the same in ratio;
    if rectnagular, it'll be padded evenly to become a squared one.
    '''
    # Get the dimensions the image
    old_size = img.size

    # Define the desired size to transform the image to
    desired_size = (64,64)

    # Calculate the maximum dimension of the original image
    max_dim = max(old_size)

    # Create a new image with the max_dim as the width and height
    padded = Image.new("RGB", (max_dim, max_dim))

    # Calculate the padding for the image to make it square
    x = (max_dim - old_size[0]) // 2
    y = (max_dim - old_size[1]) // 2

    # Paste the original image onto the padded image at the calculated position
    padded.paste(img, (x, y))

    # Resize the padded image to the desired size
    out_img = padded.resize(desired_size)

    # Return the transformed image
    return out_img

def extract_obj(img, annotations):
    '''
    This function extracts objects from an image based on provided annotations
    '''
    # Define lists to keep objects in an image and their labels
    objects = []
    labels = []

    # Loop through annotations, each of which contain a label and
    # a bounding box denoted by 'b_box'
    for label, b_box in annotations:
        labels.append(label)
        roi = img.crop(b_box)

        # Add roi to the list
        objects.append(roi)


    # Convert labels to numpy array
    labels = np.array(labels)

    # Return objects as individual images as well as their labels
    return objects, labels

def preprocessing(data):

    # Define two temporary lists to store objects and labels
    X_temp = []
    y_temp = []

    # Iterate over images and annotations to prepare X_train and y_train
    for img, annotations in data:

        # Extract the objects from current image
        objects, labels = extract_obj(img, annotations)

        # Pad objects
        padded = []
        for obj in objects:
            padded_img = pad_img(obj)
            padded.append(padded_img)

        # Add the objects to two temporary lists
        X_temp.append(padded)
        y_temp.append(labels)

    # Flatten the list of labels and convert to numpy array
    orig_labels = list(itertools.chain(*y_temp))
    orig_labels_np = np.array(orig_labels).reshape(-1, 1)

    # Encode the labels
    encoder = OneHotEncoder()
    y = encoder.fit_transform(orig_labels_np).toarray()

    n_channels = 3

    X_list = []

    # Normalize and create a list of image arrays
    for img in X_temp:
        for obj in img:
            X_list.append(np.array(obj)/255.0)

    # Convert the list of images to an array
    X = np.array(X_list)

    return X, y, orig_labels_np

# Get features and labels
X, y, orig_labels = preprocessing(train_data)
n_labels = y.shape[1]

# Display some of the padded objects
fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(10, 3))
ax0.imshow(X[np.argmin(train_obj_dims)//2], cmap='gray')
ax1.imshow(X[30], cmap='gray')
ax2.imshow(X[np.argmax(train_obj_dims)//2], cmap='gray')

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=42)

# Shape check
print(Back.RESET + Fore.YELLOW + f"X_train.shape: {X_train.shape}")
print(f"y_train.shape: {y_train.shape}")
print(Back.RESET + Fore.YELLOW + f"X_test.shape: {X_test.shape}")
print(f"y_test.shape: {y_test.shape}")

# Define a model-building function
def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Conv2D(32, (3, 3), activation='relu',
                            input_shape=(64, 64, 3)))
    model.add(layers.AveragePooling2D((2, 2)))

    # Tune the number of convolutional layers
    for i in range(hp.Int('conv_layers', 1, 3)):
        model.add(layers.Conv2D(hp.Int(f'filters_{i}', 32, 128, step=32),
                                (3, 3), activation='relu'))
        model.add(layers.AveragePooling2D((2, 2)))

    model.add(layers.Flatten())

    # Tune the number of units in the dense layer
    model.add(layers.Dense(hp.Int('units', 64, 256, step=32),
                           activation='relu'))

    # Add a dropout layer
    model.add(layers.Dropout(hp.Float('dropout', 0.3, 0.6, step=0.1)))

    # Tune the learning rate for the optimizer
    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])
    optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate)

    model.add(layers.Dense(n_labels, activation='softmax'))

    model.compile(optimizer=optimizer,
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])


    return model

# Create a KerasTuner Hyperband tuner
n_labels = y_train.shape[1]
tuner = kt.Hyperband(
    build_model,
    objective='val_accuracy',
    max_epochs=100,
    directory='my_dir',
    project_name='my_project'
)

# Perform the hyperparameter search
tuner.search(X_train, y_train, epochs=40, validation_data=(X_test, y_test))

bhbb

# Print the best hyperparameters found
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(f"Best Hyperparameters: {best_hps}")

# Build and train the model with the best hyperparameters
model = tuner.hypermodel.build(best_hps)
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))

## Test the model
# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)

# Visualize the model
plot_model(model, to_file='basic_model.png')
SVG(model_to_dot(model).create(prog='dot', format='svg'))

# Summarize the model
model.summary()

# Print test loss and accuracy
print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")

# Assuming y_test and y_pred are the true labels and predicted labels respectively
##y_pred = model.predict(X_test)
#y_pred_classes = y_pred.argmax(axis=1)  # Assuming you have categorical output

# Calculate additional metrics
#recall = recall_score(y_test, y_pred_classes)
#precision = precision_score(y_test, y_pred_classes)
#iou = jaccard_score(y_test, y_pred_classes)

#print(f"Recall: {recall}")
#print(f"Precision: {precision}")
#print(f"IOU: {iou}")

predictions = model.predict(X_test)

# Create a new instance of OneHotEncoder
encoder = OneHotEncoder()

# Fit the encoder on the original categorical labels
encoder.fit(orig_labels)

# Perform the inverse transformation using the OneHotEncoder
y_orig_true = encoder.inverse_transform(y_test)
y_orig_pred = encoder.inverse_transform(predictions)

# Display 16 predictions

# Set up the subplots
fig, axs = plt.subplots(4, 4, figsize=(10, 10))
axs = axs.ravel()

# Generate some random indices
random_numbers = []
for _ in range(16):
    random_number = random.randint(0, X_test.shape[0])
    random_numbers.append(random_number)

for i, rand in enumerate(random_numbers):
    axs[i].imshow(X_test[rand], cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(f"True value: {y_orig_true[rand]}\n Predicted value: {y_orig_pred[rand]}")

plt.tight_layout()
plt.show()

# Plot the performance of the model
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='lower right')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import precision_recall_curve, roc_curve, auc
from sklearn.preprocessing import label_binarize

# Assuming model, X_train, y_train, X_test, y_test are already defined and the model is trained

# Train the model and save the history
history = model.fit(X_train, y_train, validation_split=0.2, epochs=40, batch_size=32)

# Predict the classes
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

# Calculate confusion matrix
cm = confusion_matrix(y_test_classes, y_pred_classes)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

# Plot precision-recall curve
y_test_bin = label_binarize(y_test_classes, classes=np.arange(len(np.unique(y_test_classes))))
n_classes = y_test_bin.shape[1]

plt.figure()
for i in range(n_classes):
    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_pred[:, i])
    plt.plot(recall, precision, lw=2, label=f'class {i}')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="best")
plt.show()

# Plot ROC curve
plt.figure()
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'class {i} (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend(loc="best")
plt.show()
for fp_rate in fpr:
    print(f"False Positive Rate: {fp_rate}")

# Print final test metrics
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
recall = recall_score(y_test_classes, y_pred_classes, average='macro')
precision = precision_score(y_test_classes, y_pred_classes, average='macro')
iou = jaccard_score(y_test_classes, y_pred_classes, average='macro')

print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")
print(f"Recall: {recall}")
print(f"Precision: {precision}")
print(f"IOU: {iou}")
print(f"false positive rate: {fpr}")



import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, average_precision_score
from sklearn.preprocessing import label_binarize

# Assuming model, X_test, y_test are already defined and the model is trained

# Predict the classes
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test, axis=1)

# Binarize the test labels
y_test_bin = label_binarize(y_test_classes, classes=np.arange(len(np.unique(y_test_classes))))
n_classes = y_test_bin.shape[1]

# Calculate precision-recall curve and average precision for each class
precision = dict()
recall = dict()
average_precision = dict()

for i in range(n_classes):
    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_pred[:, i])
    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred[:, i])

# Compute mean average precision
mean_average_precision = np.mean(list(average_precision.values()))

# Plot precision-recall curve for each class
plt.figure()
for i in range(n_classes):
    plt.plot(recall[i], precision[i], lw=2, label=f'class {i} (AP = {average_precision[i]:.2f})')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="best")
plt.show()

# Print final test metrics
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
recall_metric = recall_score(y_test_classes, y_pred_classes, average='macro')
precision_metric = precision_score(y_test_classes, y_pred_classes, average='macro')
iou = jaccard_score(y_test_classes, y_pred_classes, average='macro')

print(f"Test Loss: {loss}")
print(f"Test Accuracy: {accuracy}")
print(f"Recall: {recall_metric}")
print(f"Precision: {precision_metric}")
print(f"IOU: {iou}")
print(f"Mean Average Precision (mAP): {mean_average_precision:.2f}")

import cv2
import numpy as np
import matplotlib.pyplot as plt

def show_images(images, titles):
    plt.figure(figsize=(16, 8))
    for i, (image, title) in enumerate(zip(images, titles)):
        plt.subplot(1, len(images), i + 1)
        plt.imshow(image, cmap='gray')
        plt.title(title)
        plt.axis('off')
    plt.show()

# Load an image
image = cv2.imread('/content/drive/MyDrive/MAR20/JPEGImages/1.jpg', cv2.IMREAD_GRAYSCALE)

# Apply Gaussian Blur
gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)

# Apply Median Filtering
#median_blur = cv2.medianBlur(image, 5)

# Apply Bilateral Filtering
#bilateral_filter = cv2.bilateralFilter(image, 9, 75, 75)

# Show the original and processed images
titles = ['Original Image', 'Gaussian Blur']
images = [image, gaussian_blur]

show_images(images, titles)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# ... (your existing code) ...

# Calculate confusion matrix
cm = confusion_matrix(y_test_classes, y_pred_classes)

# Display the confusion matrix directly
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()


# Calculate overall TP, FP, TN, FN for multi-class classification
FP = cm.sum(axis=0) - np.diag(cm)
FN = cm.sum(axis=1) - np.diag(cm)
TP = np.diag(cm)
TN = cm.sum() - (FP + FN + TP)

# Sum across all classes to get overall values
overall_TP = TP.sum()
overall_FP = FP.sum()
overall_TN = TN.sum()
overall_FN = FN.sum()

# Calculate overall FPR
overall_FPR = overall_FP / (overall_FP + overall_TN) if (overall_FP + overall_TN) > 0 else 0

print(f"Overall True Positives (TP): {overall_TP}")
print(f"Overall False Positives (FP): {overall_FP}")
print(f"Overall True Negatives (TN): {overall_TN}")
print(f"Overall False Negatives (FN): {overall_FN}")
print(f"Overall False Positive Rate (FPR): {overall_FPR}")

# ... (rest of your code) ...

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# ... (your existing code) ...

# Calculate confusion matrix
cm = confusion_matrix(y_test_classes, y_pred_classes)

# Display the confusion matrix directly
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()


# Calculate overall TP, FP, TN, FN for multi-class classification
FP = cm.sum(axis=0) - np.diag(cm)
FN = cm.sum(axis=1) - np.diag(cm)
TP = np.diag(cm)
TN = cm.sum() - (FP + FN + TP)

# Sum across all classes to get overall values
overall_TP = TP.sum()
overall_FP = FP.sum()
overall_TN = TN.sum()
overall_FN = FN.sum()

# Calculate overall FPR in percentage
overall_FPR = overall_FP / (overall_FP + overall_TN) if (overall_FP + overall_TN) > 0 else 0
overall_FPR_percentage = overall_FPR * 100

print(f"Overall True Positives (TP): {overall_TP}")
print(f"Overall False Positives (FP): {overall_FP}")
print(f"Overall True Negatives (TN): {overall_TN}")
print(f"Overall False Negatives (FN): {overall_FN}")
print(f"Overall False Positive Rate (FPR): {overall_FPR}")
print(f"Overall False Positive Rate (FPR) in percentage: {overall_FPR_percentage:.2f}%")

# ... (rest of your code) ...

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# ... (your existing code) ...

# Find the number of layers in the model
num_layers = len(model.layers)
print(f"Number of layers in the model: {num_layers}")

all_filters = []

for layer in model.layers:
    if isinstance(layer, keras.layers.Conv2D):  # Check if the layer is a Conv2D layer
        filters, biases = layer.get_weights()
        all_filters.append(filters)  # Append the filters to the list
print(filters)
# Now, all_filters contains a list of filter arrays from all Conv2D layers

for layer in model.layers:
    if isinstance(layer, keras.layers.Conv2D):
        strides = layer.strides
        print(f"Strides for layer {layer.name}: {strides}")

input_shape = model.input_shape
print(f"Input shape of the model: {input_shape}")

input_shape = model.input_shape
print(f"Input shape of the model: {input_shape}")

# Extract the image dimensions (height, width, channels)
height = input_shape[1]
width = input_shape[2]
channels = input_shape[3]  # If the model expects color images

print(f"Original image size: {width} x {height} pixels")
print(f"Number of channels: {channels}")

model_name = model.name
print(f"Model name: {model_name}")